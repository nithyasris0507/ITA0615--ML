import math
from collections import Counter

class Node:
    def __init__(self, feature=None, value=None, results=None, children=None):
        self.feature = feature
        self.value = value
        self.results = results
        self.children = children or []

def entropy(data):
    counts = Counter([row[-1] for row in data])
    entropy_val = 0.0
    total = len(data)
    for count in counts.values():
        p = count / total
        entropy_val -= p * math.log2(p)
    return entropy_val

def split_data(data, feature_index):
    splits = {}
    for row in data:
        value = row[feature_index]
        if value not in splits:
            splits[value] = []
        splits[value].append(row)
    return splits

def information_gain(data, feature_index):
    total_entropy = entropy(data)
    splits = split_data(data, feature_index)
    weighted_entropy = 0.0
    total = len(data)
    
    for value, subset in splits.items():
        p = len(subset) / total
        weighted_entropy += p * entropy(subset)
    
    return total_entropy - weighted_entropy

def choose_best_feature(data):
    num_features = len(data[0]) - 1
    best_gain = 0.0
    best_feature = -1
    
    for i in range(num_features):
        gain = information_gain(data, i)
        if gain > best_gain:
            best_gain = gain
            best_feature = i
    
    return best_feature

def build_tree(data):
    if len(data) == 0:
        return Node()
    
    if all(row[-1] == data[0][-1] for row in data):
        return Node(results=data[0][-1])
    
    best_feature = choose_best_feature(data)
    if best_feature == -1:
        return Node(results=Counter([row[-1] for row in data]).most_common(1)[0][0])
    
    node = Node(feature=best_feature)
    splits = split_data(data, best_feature)
    
    for value, subset in splits.items():
        child = build_tree(subset)
        child.value = value
        node.children.append(child)
    
    return node

def classify(tree, sample):
    if tree.results is not None:
        return tree.results
    
    for child in tree.children:
        if sample[tree.feature] == child.value:
            return classify(child, sample)
    
    return "Unknown"

def print_tree(node, depth=0):
    if node.results is not None:
        print("  " * depth + f"Class: {node.results}")
        return
    
    print("  " * depth + f"Feature {node.feature}:")
    for child in node.children:
        print("  " * (depth + 1) + f"Value: {child.value}")
        print_tree(child, depth + 2)

def main():
    training_data = [
        ['Sunny', 'Hot', 'High', 'Weak', 'No'],
        ['Sunny', 'Hot', 'High', 'Strong', 'No'],
        ['Overcast', 'Hot', 'High', 'Weak', 'Yes'],
        ['Rain', 'Mild', 'High', 'Weak', 'Yes'],
        ['Rain', 'Cool', 'Normal', 'Weak', 'Yes'],
        ['Rain', 'Cool', 'Normal', 'Strong', 'No'],
        ['Overcast', 'Cool', 'Normal', 'Strong', 'Yes'],
        ['Sunny', 'Mild', 'High', 'Weak', 'No'],
        ['Sunny', 'Cool', 'Normal', 'Weak', 'Yes'],
        ['Rain', 'Mild', 'Normal', 'Weak', 'Yes'],
        ['Sunny', 'Mild', 'Normal', 'Strong', 'Yes'],
        ['Overcast', 'Mild', 'High', 'Strong', 'Yes'],
        ['Overcast', 'Hot', 'Normal', 'Weak', 'Yes'],
        ['Rain', 'Mild', 'High', 'Strong', 'No']
    ]
    
    features = ['Outlook', 'Temperature', 'Humidity', 'Wind']
    
    print("Training Data:")
    for i, row in enumerate(training_data):
        print(f"Example {i+1}: {row}")
    
    tree = build_tree(training_data)
    
    print("\nDecision Tree:")
    print_tree(tree)
    
    test_samples = [
        ['Sunny', 'Cool', 'High', 'Strong'],
        ['Rain', 'Mild', 'Normal', 'Weak'],
        ['Overcast', 'Hot', 'Normal', 'Strong']
    ]
    
    print("\nClassification Results:")
    for i, sample in enumerate(test_samples):
        result = classify(tree, sample)
        print(f"Sample {i+1}: {sample} -> {result}")

if __name__ == "__main__":
    main()
